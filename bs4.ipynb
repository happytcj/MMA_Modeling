{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import numpy as np\n",
    "import scraperwiki\n",
    "import urllib2\n",
    "import urllib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'http://www.ufc.com/rankings?fb_comment_id=6086517324953#f391bfa61a74bf2'\n",
    "html = scraperwiki.scrape(url)\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "page = urllib2.urlopen(url)\n",
    "soup = BeautifulSoup(page.read(), 'lxml')\n",
    "# print soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tables = soup.find_all('div', {'class': 'ranking-list tall'})\n",
    "tables.extend(soup.find_all('div', {'class': 'ranking-list tall center-row'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fighters = []\n",
    "for table in tables:\n",
    "    wcname = str(table.find('div', {'class': 'weight-class-name'}).contents[0]).strip()\n",
    "    if 'Pound-for-Pound' in wcname:\n",
    "        continue\n",
    "    else:\n",
    "#         print table.a.contents[0]\n",
    "        fighters.append(table.a.contents[0])\n",
    "        other_ranked = table.find_all('td', {'class': 'name-column'})\n",
    "        for ranked in other_ranked:\n",
    "            print ranked.a.contents[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fighters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = []\n",
    "for table in tables:\n",
    "    all_td = table.find_all('a')\n",
    "    all_td_str = set([x.string for x in all_td if x.string is not None])\n",
    "    all_td_str = [x.encode('utf-8').strip() for x in all_td_str if 'County' not in x]\n",
    "    all_td_str = [x for x in all_td_str if 'District' not in x and 'spade' not in x and 'Piercer' not in x and '\\xbc' not in x and 'Generals' not in x and 'Marquis' not in x]\n",
    "    all_td_str = [x for x in all_td_str if 'home' not in x and 'Yama' not in x]\n",
    "    all_td_str = [x for x in all_td_str if 'Spade' not in x]\n",
    "    all_td_str = [x for x in all_td_str if ' ' in x]\n",
    "    all_td_str = [[x] for x in all_td_str if len(x.split(' ')) < 4]\n",
    "    names += all_td_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./chinese_names.csv', 'w') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for year in range(1880, 1930):\n",
    "    post_params = {\n",
    "    'top' : '100',\n",
    "    'year' : str(year)\n",
    "    }\n",
    "    post_args = urllib.urlencode(post_params)\n",
    "    urllib2.urlopen(url, post_args)\n",
    "    headers = {\n",
    "        'Accept' : 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "        'Accept-Language' : 'en-US,en;q=0.5',\n",
    "        'Connection' : 'keep-alive',\n",
    "        'Host' : 'www.ssa.gov',\n",
    "        'Referer' : 'http://www.ssa.gov/cgi-bin/popularnames.cgi',\n",
    "        'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:21.0) Gecko/20100101 Firefox/21.0'\n",
    "        }\n",
    "\n",
    "    # With POST data:\n",
    "    page = urllib.urlopen(url, post_args, headers)\n",
    "    soup = BeautifulSoup(page.read(), 'lxml')\n",
    "    rank = soup.find('table', {'border': '1', 'bordercolor' : '#aaaabb'})\n",
    "    all_td = rank.find_all('td')\n",
    "    all_td_str = [x.string for x in all_td]\n",
    "    all_td_str.pop(-1)\n",
    "    B = np.reshape(all_td_str, (-1, 3))\n",
    "    B = [list(x)[1:] for x in B]\n",
    "    \n",
    "    with open('./names/'+str(year)+'_names.csv', 'w') as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerows(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
