{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(300000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 300 seconds\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "%autosave 300\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.preprocessing import scale, Normalizer, normalize, scale, MinMaxScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_selection import chi2\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import linear_model\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (16, 8)\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['text.usetex'] = False\n",
    "plt.rcParams['axes.labelsize'] = plt.rcParams['font.size']\n",
    "plt.rcParams['axes.titlesize'] = 1.5*plt.rcParams['font.size']\n",
    "plt.rcParams['legend.fontsize'] = 16\n",
    "plt.rcParams[\"figure.facecolor\"] = 'white'\n",
    "\n",
    "import matplotlib\n",
    "params = {'axes.labelsize': 18,'axes.titlesize':20, 'legend.fontsize': 20, 'xtick.labelsize': 16, 'ytick.labelsize': 16}\n",
    "matplotlib.rcParams.update(params)\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "num_splits = 5.0\n",
    "kf = KFold(n_splits=int(num_splits))\n",
    "\n",
    "raw_data = pd.read_csv('data/fighter_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2455, 19)\n",
      "(2071, 19)\n"
     ]
    }
   ],
   "source": [
    "df_5w = raw_data[((raw_data['w'].astype(int)+raw_data['l'].astype(float)+raw_data['d'].astype(float)) >= 5)]\n",
    "df_5w.reset_index(drop=True, inplace=True)\n",
    "print(df_5w.shape)\n",
    "significant_df = df_5w[(df_5w['SLpM']\n",
    "           + df_5w['Str. Acc.'].apply(lambda x: x.strip('%')).astype(float)\n",
    "           + df_5w['SApM']\n",
    "           + df_5w['Str. Def'].apply(lambda x: x.strip('%')).astype(float)\n",
    "           + df_5w['TD Avg']\n",
    "           + df_5w['TD Acc.'].apply(lambda x: x.strip('%')).astype(float)\n",
    "           + df_5w['TD Def.'].apply(lambda x: x.strip('%')).astype(float)\n",
    "           + df_5w['Sub. Avg.']) > 0\n",
    "          ]\n",
    "significant_df.reset_index(drop=True, inplace=True)\n",
    "#Get rid of rows from fightmatrix that are all zeros\n",
    "print (significant_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2071, 8)\n"
     ]
    }
   ],
   "source": [
    "def extract_stats_df(input_df):\n",
    "    df = input_df.filter(['SLpM','Str. Acc.','SApM', 'Str. Def', 'TD Avg', \n",
    "                                     'TD Acc.', 'TD Def.', 'Sub. Avg.'], \n",
    "                                     axis=1)\n",
    "    df['Str. Acc.'] = df['Str. Acc.'].apply(lambda x: x.strip('%')).astype(float)\n",
    "    df['Str. Def'] = df['Str. Def'].apply(lambda x: x.strip('%')).astype(float)\n",
    "    df['TD Acc.'] = df['TD Acc.'].apply(lambda x: x.strip('%')).astype(float)\n",
    "    df['TD Def.'] = df['TD Def.'].apply(lambda x: x.strip('%')).astype(float)\n",
    "    return df\n",
    "stats_df = extract_stats_df(significant_df)\n",
    "print(stats_df.shape)\n",
    "stats_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = ['SLpM','Str. Acc.','SApM', 'Str. Def', 'TD Avg', 'TD Acc.', 'TD Def.', 'Sub. Avg.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153, 19)\n"
     ]
    }
   ],
   "source": [
    "#load the current top15 ranked fighters in all divisions\n",
    "top15_all_class = np.genfromtxt('./data/top15.csv', delimiter=',', dtype='str')\n",
    "significant_df = df_5w[(df_5w['SLpM']\n",
    "           + df_5w['Str. Acc.'].apply(lambda x: x.strip('%')).astype(float)\n",
    "           + df_5w['SApM']\n",
    "           + df_5w['Str. Def'].apply(lambda x: x.strip('%')).astype(float)\n",
    "           + df_5w['TD Avg']\n",
    "           + df_5w['TD Acc.'].apply(lambda x: x.strip('%')).astype(float)\n",
    "           + df_5w['TD Def.'].apply(lambda x: x.strip('%')).astype(float)\n",
    "           + df_5w['Sub. Avg.']) > 0\n",
    "          ]\n",
    "significant_df.reset_index(drop=True, inplace=True)\n",
    "top15_df = significant_df[(significant_df['first'] + ' ' + significant_df['last']).isin(top15_all_class)]\n",
    "print(top15_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "top15_names_df = (top15_df['first'] + ' ' + top15_df['last']).values\n",
    "reach_op = lambda x: float(x.replace('\"', '').strip())\n",
    "# weight_op = lambda x: float(x.split()[0])\n",
    "stracc_op = lambda x: float(x[:-1])\n",
    "def height_op(in_str):\n",
    "    in_str = str(in_str)\n",
    "    if type(in_str) is int:\n",
    "        return in_str\n",
    "    feet, inches = in_str.split(' ')\n",
    "    feet_num = int(feet[:-1])\n",
    "    inches_num = int(inches[:-1])\n",
    "    return feet_num * 12 + inches_num\n",
    "def result_op(in_str):\n",
    "    if 'win' in in_str:\n",
    "        return 1\n",
    "    elif 'loss' in in_str:\n",
    "        return 0\n",
    "    elif 'n/a' in in_str:\n",
    "        return 0\n",
    "def cleanup_df(indf):\n",
    "    ret = pd.DataFrame()\n",
    "    indf.dropna(subset=['height', 'reach'], inplace=True)\n",
    "    ret['reach'] = indf['reach'].apply(reach_op)\n",
    "#     ret['weight'] = indf['weight'].apply(weight_op)\n",
    "    ret['height'] = indf['height'].apply(height_op)\n",
    "    ret['w/l'] = indf['w']/(indf['w']+indf['l'])\n",
    "    ret['SLpM'] = indf['SLpM']\n",
    "    ret['Str. Acc.'] = indf['Str. Acc.'].apply(stracc_op)\n",
    "    ret['SApM'] = indf['SApM'].apply(float)\n",
    "    ret['Str. Def'] = indf['Str. Def'].apply(stracc_op)\n",
    "    ret['TD Avg'] = indf['TD Avg'].apply(float)\n",
    "    ret['TD Acc.'] = indf['TD Acc.'].apply(stracc_op)\n",
    "    ret['TD Def.'] = indf['TD Def.'].apply(stracc_op)\n",
    "    ret['Sub. Avg.'] = indf['Sub. Avg.'].apply(float)\n",
    "    ret['result'] = indf['result'].apply(result_op)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new vector consisting of: height, weight, reach, w/l ratio, and statistics\n",
    "def generate_delta(primary, contender, mode='absolute'):\n",
    "    #first cleanup input dataframes\n",
    "    primary_clean = cleanup_df(primary)\n",
    "    contender_clean = cleanup_df(contender)\n",
    "    if mode == 'absolute':\n",
    "        delta = pd.DataFrame(data = (contender_clean.values-primary_clean.values),\n",
    "                             columns=contender_clean.columns)\n",
    "    elif mode == 'percentage':\n",
    "        delta = pd.DataFrame(100*(contender_clean.values-primary_clean.values)/primary_clean.values,\n",
    "                             columns=contender_clean.columns)\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top15 Fighters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1903, 7)\n"
     ]
    }
   ],
   "source": [
    "df_top15 = pd.read_csv('./data/top15_results.csv', delimiter=',', header=None)\n",
    "df_top15.columns = ['red', 'blue', 'result']\n",
    "df_top15['red_first'] = df_top15['red'].str.split(' ', expand=True)[0]\n",
    "def get_last_name(x):\n",
    "    return x.split(' ')[-1]\n",
    "df_top15['red_last'] = df_top15['red'].apply(get_last_name)\n",
    "df_top15['blue_first'] = df_top15['blue'].str.split(' ', expand=True)[0]\n",
    "df_top15['blue_last'] = df_top15['blue'].apply(get_last_name)\n",
    "top15_list = df_top15['red'].unique()\n",
    "print(df_top15.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brandon Moreno\n",
      "Chan Jung\n",
      "Rafael Anjos\n",
      "Dong Kim\n",
      "David Branch\n",
      "Volkan Oezdemir\n",
      "Ovince Preux\n",
      "Cynthia Calvillo\n",
      "Germaine Randamie\n",
      "Ketlen Vieira\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "To generate deltas, loop through the top fighters one by one and concatenate deltas results\n",
    "'''\n",
    "frames = []\n",
    "for fighter in top15_list:\n",
    "    try:\n",
    "        df_fighter = df_top15[df_top15['red'] == fighter]\n",
    "        first = df_fighter['red_first'].values[0]\n",
    "        last = df_fighter['red_last'].values[0]\n",
    "        fighter_stats = df_5w[(df_5w['first'] == first) & (df_5w['last'] == last)]\n",
    "#         print(fighter_stats.isnull().values.any())\n",
    "        fighter_stats['result'] = 'n/a'\n",
    "        opponent_stats = pd.merge(df_5w, df_fighter, left_on=['first', 'last'], right_on=['blue_first', 'blue_last'], how='inner')\n",
    "        fighter_deltas = generate_delta(fighter_stats, opponent_stats)\n",
    "        frames.append(fighter_deltas)\n",
    "    except Exception as e:\n",
    "#         print e\n",
    "        print (first, last)\n",
    "        pass\n",
    "#         display(fighter_stats)\n",
    "#         display(opponent_stats)\n",
    "# fighter_deltas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1546, 12)\n",
      "(1525, 12)\n"
     ]
    }
   ],
   "source": [
    "df_deltas_top15 = pd.concat(frames)\n",
    "print(df_deltas_top15.shape)\n",
    "df_deltas_top15.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# Need to figure out why there are NAN results\n",
    "df_deltas_top15.dropna(inplace=True)\n",
    "print(df_deltas_top15.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictors = df_deltas_top15.iloc[:,:-1]\n",
    "train_response = df_deltas_top15['result']\n",
    "X = train_predictors.values\n",
    "y = train_response.values\n",
    "print (X.shape)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_misclassified = 0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    clf = RandomForestClassifier(n_jobs=-1, max_features=5, n_estimators=500)\n",
    "    y_pred = clf.fit(x_train, y_train).predict(x_test)\n",
    "    percent_misclassified+=100*(y_test != y_pred).sum()/float(x_test.shape[0])\n",
    "#     print(\"mislabeled out of %d obs : %0.2f\"% (x_test.shape[0], 100*(y_test != y_pred).sum()/float(x_test.shape[0])))\n",
    "print(\"avg misclassification: %0.2f\"%float(percent_misclassified/num_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.fit(X, y)\n",
    "#try a prediction\n",
    "conor_stats = df_5w[(df_5w['first'] == 'Conor') & (df_5w['last'] == 'McGregor')]\n",
    "nate_stats = df_5w[(df_5w['first'] == 'Khabib') & (df_5w['last'] == 'Nurmagomedov')]\n",
    "conor_stats.loc[:,'result'] = 'n/a'\n",
    "nate_stats.loc[:,'result'] = 'n/a'\n",
    "try_delta = generate_delta(conor_stats, nate_stats).iloc[:,:-1].values\n",
    "model.predict(try_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the model with Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open(\"random_forest_model.pkl\", \"wb\"))\n",
    "pickle.dump(df_5w, open('df_5w.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create normalized df for radar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2455, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "def cleanup_df_wnames(indf):\n",
    "    ret = pd.DataFrame()\n",
    "    indf.dropna(subset=['height', 'reach'], inplace=True)\n",
    "    ret['first'] = indf['first']\n",
    "    ret['last'] = indf['last']\n",
    "#     ret['reach'] = indf['reach'].apply(reach_op)\n",
    "#     ret['weight'] = indf['weight'].apply(weight_op)\n",
    "#     ret['height'] = indf['height'].apply(height_op)\n",
    "    ret['w/l'] = indf['w']/(indf['w']+indf['l'])\n",
    "    ret['SLpM'] = indf['SLpM']\n",
    "    ret['Str. Acc.'] = indf['Str. Acc.'].apply(stracc_op)\n",
    "    ret['SApM'] = indf['SApM'].apply(float)\n",
    "    ret['Str. Def'] = indf['Str. Def'].apply(stracc_op)\n",
    "    ret['TD Avg'] = indf['TD Avg'].apply(float)\n",
    "    ret['TD Acc.'] = indf['TD Acc.'].apply(stracc_op)\n",
    "    ret['TD Def.'] = indf['TD Def.'].apply(stracc_op)\n",
    "    ret['Sub. Avg.'] = indf['Sub. Avg.'].apply(float)\n",
    "    return ret\n",
    "print(df_5w.shape)\n",
    "df_abs = cleanup_df_wnames(df_5w)\n",
    "df_abs.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1183, 11)\n"
     ]
    }
   ],
   "source": [
    "cols_of_interest = ['w/l', 'SLpM', 'Str. Acc.', 'SApM', 'Str. Def', 'TD Avg', 'TD Acc.',\n",
    "            'TD Def.', 'Sub. Avg.']\n",
    "x = df_abs[cols_of_interest].values #returns a numpy array\n",
    "print(df_abs.shape)\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df_norm = pd.DataFrame(x_scaled, columns=cols_of_interest)\n",
    "df_norm['first'] = df_abs['first']\n",
    "df_norm['last'] = df_abs['last']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All bouts model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv('./data/full_results.csv', delimiter=',', header=None)\n",
    "df_full.columns = ['red', 'blue', 'result']\n",
    "df_full['red_first'] = df_full['red'].str.split(' ', expand=True)[0]\n",
    "def get_last_name(x):\n",
    "    return x.split(' ')[-1]\n",
    "df_full['red_last'] = df_full['red'].apply(get_last_name)\n",
    "df_full['blue_first'] = df_full['blue'].str.split(' ', expand=True)[0]\n",
    "df_full['blue_last'] = df_full['blue'].apply(get_last_name)\n",
    "full_list = df_full['red'].unique()\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "To generate deltas, loop through the top fighters one by one and concatenate deltas results\n",
    "'''\n",
    "frames = []\n",
    "for fighter in full_list:\n",
    "    try:\n",
    "        df_fighter = df_full[df_full['red'] == fighter]\n",
    "        first = df_fighter['red_first'].values[0]\n",
    "        last = df_fighter['red_last'].values[0]\n",
    "        fighter_stats = df_5w[(df_5w['first'] == first) & (df_5w['last'] == last)]\n",
    "        fighter_stats.isnull().values.any()\n",
    "        fighter_stats['result'] = 'n/a'\n",
    "        opponent_stats = pd.merge(df_5w, df_fighter, left_on=['first', 'last'], right_on=['blue_first', 'blue_last'], how='inner')\n",
    "        fighter_deltas = generate_delta(fighter_stats, opponent_stats)\n",
    "        frames.append(fighter_deltas)\n",
    "    except:\n",
    "        print (first, last)\n",
    "#         display(fighter_stats)\n",
    "#         display(opponent_stats)\n",
    "# fighter_deltas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deltas_full = pd.concat(frames)\n",
    "df_deltas_full.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "#Need to figure out why there are NAN results\n",
    "df_deltas_full.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_list = ['Danny Abbadi','David Abbott','Daniel Acacio','Mike Aina','Hitomi Akano','Razak Al-Hassan','Gilbert Aldana','Kenneth Alexander','Marcio Junior','Olaf Alfonso','Amilcar Alves','Andre Amado','Karl Amoussou','Reese Andy','Shinya Aoki','Erik Apple','Ricardo Arona','Pat Audinwood','Luiz Azeredo','Bryan Baker','Tae Bang','David Baron','Lyle Beerbohm','Charles Bennett','Steve Berger','Bret Bergmark','Keith Berry','Edson Berto','Jason Black','Jesse Bongfeldt','Paul Bradley','Ebenezer Braga','Joe Brammer','Chris Brennan','Aaron Brink','Todd Brown','Steve Bruno','Courtney Buck','Murilo Bustamante','Gina Carano','Phil Cardella','Antonio Junior','Shonie Carter','Bendy Casimir','Luke Caudillo','Ansar Chalangov','Joachim Christensen','Heather Clark','Wayne Cole','Devin Cole','Kit Cope','Muhsin Corbbrey','Wesley Correira','Jeff Cox','Dan Cramer','Alberto Crane','Richard Crunkilton','Marcio Cruz','Philip Fries','Chris Rocha','Mike Torre','Rodrigo Lima','Edilberto Oliveira','Jorge Oliveira','Germaine Randamie','Shane Rosario','Jon Reyes','Thomas Denny','Cory Devela','Edwin DeWees','Alessio Chirico','Rafael Dias','Kyle Dietz','Rafael Anjos','Junior Santos','Antonio Santos','Robert Drysdale','Joe Duarte','Justin Eilers','Jon Einemo','Aleksander Emelianenko','Tom Erikson','Doug Evans','Dan Evensen','Tonya Evinger','Edward Faaloloto','Brodie Farber','Kevin Ferguson','Bibiano Fernandes','Anthony Figueroa','Paulo Filho','Mirko Cop','Jan Finney','Luiz Firmino','Xavier Foupa-Pokam','Ian Freeman','Don Frye','Tony Fryklund','Kazuyuki Fujita','Travis Galbraith','Andre Galvao','Marcos Galvao','Joey Gambino','Brian Gassaway','Tiki Ghosn','Jason Gilliam','Clint Godfrey','Allan Goes','Gary Goodridge','Chase Gormley','Damian Grabowski','Royce Gracie','Renzo Gracie','Andre Gusmao','John Halverson','Joachim Hansen','Justin Haskins','Josh Haynes','Henrique Silva','Conor Heun','Branden Hinkle','Kwan Kwak','Sam Hoger','Mark Holst','Matt Horwich','John Hosman','Abongo Humphrey','Joe Hurley','Fabiano Iha','Seichi Ikemoto','Yusuke Imamura','Masakazu Imanari','Brad Imes','Enson Inoue','Mitsuhiro Ishida','Yoislandy Izquierdo','Eugene Jackson','Jeremy Jackson','Maciej Jewtuszko','Brian Johnston','Carlton Jones','Kevin Jordan','Jeff Joslin','Chan Jung','Hiromitsu Kanehara','Kyung Kang','Tetsuji Kato','CJ Keith','Mark Kerr','Sergei Kharitonov','Dong Kim','Tsuyoshi Kohsaka','John Kolosci','Yuki Kondo','Dan Lauzon','David Lee','Kimo Leopoldo','Justin Levens','Scott Lighty','Hyun Lim','Lucio Linhares','Jorge Lopez','Ian Loveland','Waylon Lowe','Mike Lullo','Adam Lynn','Bill Mahood','Melvin Manhoef','Jose Maria','Wagner Martins','Daijiro Matsui','Gan McGee','Greg McIntyre','Dave Menne','Guy Mezger','Kristof Midoux','Pat Miletich','Curtis Millender','Micah Miller','Adam Milstead','Ikuhisa Minowa','Kazuo Misaki','Dokonjonosuke Mishima','Eiji Mitsuoka','Kazuyuki Miyata','Tatsuya Mizuno','Roxanne Modafferi','Nate Moore','Brandon Moreno','Sammy Morgan','Brad Morris','Anthony Morrison','Lee Murray','Daisuke Nakamura','Jutaro Nakao','Yui Nam','Fabio Nascimento','Bobby Nash','Pawel Nastula','Dustin Neace','Antonio Neto','Carlos Newton','Yosuke Nishijima',\"TJ O'Brien\",'Jorge Oliveira','Alexander Otsuka','Shungo Oyama','Alexandre Pantoja','Bryan Pardoe','Michael Patt','Julio Paulino','Joe Pearson','Rolando Perez','Ross Pointon','Chris Price','Niko Price','Benji Radach','Jordan Radev','Hector Ramirez','Luis Ramos','Kevin Randleman','Gideon Ray','Abdul Alhassan','Chad Reiner','Jason Reinhardt','Will Ribeiro','Matt Ricehouse','Pedro Rizzo','Buddy Roberts','Colin Robinson','Carlos Rocha','Ricco Rodriguez','Marcos Lima','Jake Rosholt','Murilo Rua','Gabe Ruediger','Anthony Ruiz','Ovince Preux','Kazushi Sakuraba','Hayato Sakurai','Ivan Salaverry','Sean Salmon','Diego Saraiva','Harris Sarmiento','Masaaki Satake','Lumumba Sayers','Fabiano Scherner','Samy Schiavo','Semmy Schilt','Alex Schoenauer','Andrei Semenov','Ivan Serati','Dan Severn','Frank Shamrock','Katsuyori Shibata','Akira Shoji','Assuerio Silva','Jay Silva','Douglas Andrade','Wes Sims','Lodune Sincaid','Maurice Smith','Rameau Sokoudjou','Bobby Southworth','Chris Spang','Pete Spratt','Dion Staring','Alex Stiebling','Tyler Stinson','Dan Stittgen','Denis Stojnic','Curtis Stout','Dave Strasser','Genki Sudo','Amar Suloev','Yoshiki Takahashi','Daiju Takase','Hiroyuki Takaya','Kiyoshi Tamura','Jesse Taylor','James Huna','Tra Telligman','David Terrell','James Terry','Din Thomas','Ryan Thomas','Noah Thomas','James Thompson','Hideo Tokoro','Anthony Torres','Ronys Torres','Bryan Travers','Yasuhiro Urushitani','Victor Valimaki','Andrew Valladerez','Mike Arsdale','Matt Buren','Matt Veach','Joe Vedepo','Joe Veres','Renato Verissimo','Ketlen Vieira','Steve Vigneault','Joey Villasenor','Falaniko Vitale','Jason Flue','Igor Vovchanchyn','Donny Walker','Crafton Wallace','Joe Warren','Mark Weir','Vernon White','Mike Whitehead','Justin Wilcox','Pete Williams','Eric Wisely','Travis Wiuff','Brandon Wolff','Justin Wren','Eddie Yagin','Hirotaka Yokoi','Dong Yoon','Hidehiko Yoshida','Trenell Young','Rob Yundt','Marius Zaromskis','Roman Zentsov']\n",
    "intercepted_list = [x for x in full_list if x not in exclude_list]\n",
    "pickle.dump(intercepted_list, open('names.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5w.loc[:,'full name'] = df_5w['first'] + ' ' + df_5w['last']\n",
    "df_5w = df_5w[~df_5w['full name'].isin(exclude_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictors = df_deltas_full.iloc[:,:-1]\n",
    "train_response = df_deltas_full['result']\n",
    "X = train_predictors.values\n",
    "y = train_response.values\n",
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_misclassified = 0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    clf = RandomForestClassifier(n_jobs=-1, max_features=5, n_estimators=500)\n",
    "    y_pred = clf.fit(x_train, y_train).predict(x_test)\n",
    "    percent_misclassified+=100*(y_test != y_pred).sum()/float(x_test.shape[0])\n",
    "#     print(\"mislabeled out of %d obs : %0.2f\"% (x_test.shape[0], 100*(y_test != y_pred).sum()/float(x_test.shape[0])))\n",
    "print(\"avg misclassification: %0.2f\"%float(percent_misclassified/num_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
